{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tumor Classification with PyTorch⚡Lightning & EfficientNet\n",
    "\n",
    "The goal of this challenge is to Predict the status of a genetic biomarker important for brain cancer treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install -qU pytorch_lightning pydicom rising torchsummary\n",
    "! pip install -q https://github.com/shijianjian/EfficientNet-PyTorch-3D/archive/refs/heads/master.zip\n",
    "! pip uninstall -q -y wandb\n",
    "! ls -l /home/jovyan/work/rsna-miccai-brain-tumor\n",
    "! nvidia-smi\n",
    "! mkdir /home/jovyan/temp\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "These 3 cohorts are structured as follows: Each independent case has a dedicated folder identified by a five-digit number.\n",
    "Within each of these “case” folders, there are four sub-folders, each of them corresponding to each of the structural multi-parametric MRI (mpMRI) scans, in DICOM format.\n",
    "The exact mpMRI scans included are:\n",
    "\n",
    "- **FLAIR**: Fluid Attenuated Inversion Recovery\n",
    "- **T1w**: T1-weighted pre-contrast\n",
    "- **T1Gd**: T1-weighted post-contrast\n",
    "- **T2**: T2-weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PATH_DATASET = \"/home/jovyan/work/rsna-miccai-brain-tumor\"\n",
    "PATH_TEMP = \"/home/jovyan/temp\"\n",
    "SCAN_TYPES = (\"FLAIR\", \"T1w\", \"T1CE\", \"T2w\")\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(PATH_DATASET, \"train_labels.csv\"))\n",
    "df_train[\"BraTS21ID\"] = df_train[\"BraTS21ID\"].apply(lambda i: \"%05d\" % i)\n",
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_= df_train[\"MGMT_value\"].value_counts().plot(kind=\"pie\", title=\"label distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import torch\n",
    "import pydicom\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional, Tuple\n",
    "from pydicom.pixel_data_handlers import apply_voi_lut\n",
    "\n",
    "\n",
    "def parse_name_index(dcm_path) -> int:\n",
    "    res = re.match(r\".*-(\\d+)\\.dcm\", dcm_path).groups()\n",
    "    assert len(res) == 1\n",
    "    return int(res[0])\n",
    "\n",
    "\n",
    "def load_dicom(path_file: str) -> Optional[np.ndarray]:\n",
    "    dicom = pydicom.dcmread(path_file)\n",
    "    # TODO: adjust spacing in particular dimension according DICOM meta\n",
    "    try:\n",
    "        img = apply_voi_lut(dicom.pixel_array, dicom).astype(np.float32)\n",
    "    except RuntimeError as err:\n",
    "        print(err)\n",
    "        return None\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_volume(path_volume: str, percentile: Optional[int] = 0.01) -> Tensor:\n",
    "    path_slices = glob.glob(os.path.join(path_volume, '*.dcm'))\n",
    "    path_slices = sorted(path_slices, key=parse_name_index)\n",
    "    vol = []\n",
    "    for p_slice in path_slices:\n",
    "        img = load_dicom(p_slice)\n",
    "        if img is None:\n",
    "            continue\n",
    "        vol.append(img.T)\n",
    "    volume = torch.tensor(vol, dtype=torch.float32)\n",
    "    if percentile is not None:\n",
    "        # get extreme values\n",
    "        p_low = np.quantile(volume, percentile) if percentile else volume.min()\n",
    "        p_high = np.quantile(volume, 1 - percentile) if percentile else volume.max()\n",
    "        # normalize\n",
    "        volume = (volume.to(torch.float32) - p_low) / (p_high - p_low)\n",
    "    return volume.T\n",
    "\n",
    "\n",
    "def interpolate_volume(volume: Tensor) -> Tensor:\n",
    "    vol_shape = volume.shape\n",
    "    d_new = min(vol_shape[:2])\n",
    "    # assert vol_shape[0] == vol_shape[1], f\"mixed shape: {vol_shape}\"\n",
    "    if d_new == vol_shape[2]:\n",
    "        return volume\n",
    "    vol_size = (vol_shape[0], vol_shape[1], d_new)\n",
    "    return F.interpolate(volume.unsqueeze(0).unsqueeze(0), size=vol_size, mode=\"trilinear\", align_corners=False)[0, 0]\n",
    "\n",
    "\n",
    "def _tuple_int(t: Tensor) -> tuple:\n",
    "    return tuple(t.numpy().astype(int))\n",
    "\n",
    "def resize_volume(volume: Tensor, size: int = 128) -> Tensor:\n",
    "    shape_old = torch.tensor(volume.shape)\n",
    "    shape_new = torch.tensor([size] * 3)\n",
    "    scale = torch.max(shape_old.to(float) / shape_new)\n",
    "    shape_scale = shape_old / scale\n",
    "    # print(f\"{shape_old} >> {shape_scale} >> {shape_new}\")\n",
    "    vol_ = F.interpolate(volume.unsqueeze(0).unsqueeze(0), size=_tuple_int(shape_scale), mode=\"trilinear\", align_corners=False)[0, 0]\n",
    "    offset = _tuple_int((shape_new - shape_scale) / 2)\n",
    "    volume = torch.zeros(*_tuple_int(shape_new), dtype=torch.float32)\n",
    "    shape_scale = _tuple_int(shape_scale)\n",
    "    volume[offset[0]:offset[0]+shape_scale[0], offset[1]:offset[1]+shape_scale[1], offset[2]:offset[2]+shape_scale[2]] = vol_\n",
    "    return volume\n",
    "\n",
    "\n",
    "def find_dim_min(vec: list, thr: float) -> int:\n",
    "    high = np.array(vec) >= thr\n",
    "    return np.argmax(high)\n",
    "\n",
    "\n",
    "def find_dim_max(vec: list, thr: float) -> int:\n",
    "    high = np.array(vec) >= thr\n",
    "    return len(high) - np.argmax(high[::-1])\n",
    "\n",
    "\n",
    "def crop_volume(volume: Tensor, thr: float = 1e-6) -> Tensor:\n",
    "    dims_x = torch.sum(torch.sum(volume, 1), -1) / np.prod(volume.shape)\n",
    "    dims_y = torch.sum(torch.sum(volume, 0), -1) / np.prod(volume.shape)\n",
    "    dims_z = torch.sum(torch.sum(volume, 0), 0) / np.prod(volume.shape)\n",
    "    return volume[\n",
    "        find_dim_min(dims_x, thr):find_dim_max(dims_x, thr),\n",
    "        find_dim_min(dims_y, thr):find_dim_max(dims_y, thr),\n",
    "        find_dim_min(dims_z, thr):find_dim_max(dims_z, thr)\n",
    "    ]\n",
    "\n",
    "\n",
    "def show_volume_slice(axarr_, vol_slice, ax_name: str, v_min_max: tuple = (0., 1.)):\n",
    "    axarr_[0].set_title(f\"axis: {ax_name}\")\n",
    "    axarr_[0].imshow(vol_slice, cmap=\"gray\", vmin=v_min_max[0], vmax=v_min_max[1])\n",
    "    axarr_[1].plot(torch.sum(vol_slice, 1), list(range(vol_slice.shape[0]))[::-1])\n",
    "    axarr_[1].plot(list(range(vol_slice.shape[1])), torch.sum(vol_slice, 0))\n",
    "    axarr_[1].set_aspect('equal')\n",
    "    axarr_[1].grid()\n",
    "\n",
    "\n",
    "def idx_middle_if_none(volume: Tensor, *xyz: Optional[int]):\n",
    "    xyz = list(xyz)\n",
    "    vol_shape = volume.shape\n",
    "    for i, d in enumerate(xyz):\n",
    "        if d is None:\n",
    "            xyz[i] = int(vol_shape[i] / 2)\n",
    "        assert 0 <= xyz[i] < vol_shape[i]\n",
    "    return xyz\n",
    "\n",
    "\n",
    "def show_volume(volume: Tensor, x: Optional[int] = None, y: Optional[int] = None, z: Optional[int] = None, fig_size: Tuple[int, int] = (14, 9), v_min_max: tuple = (0., 1.),):\n",
    "    x, y, z = idx_middle_if_none(volume, x, y, z)\n",
    "    fig, axarr = plt.subplots(nrows=2, ncols=3, figsize=fig_size)\n",
    "    print(f\"share: {volume.shape}, x={x}, y={y}, z={y}  >> {volume.dtype}\")\n",
    "    show_volume_slice(axarr[:, 0], volume[x, :, :], \"X\", v_min_max)\n",
    "    show_volume_slice(axarr[:, 1], volume[:, y, :], \"Y\", v_min_max)\n",
    "    show_volume_slice(axarr[:, 2], volume[:, :, z], \"Z\", v_min_max)\n",
    "    # plt.show(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "def interactive_show(volume_path: str, crop_thr: float):\n",
    "    print(f\"loading: {volume_path}\")\n",
    "    volume = load_volume(volume_path, percentile=0)\n",
    "    print(f\"sample shape: {volume.shape} >> {volume.dtype}\")\n",
    "    volume = interpolate_volume(volume)\n",
    "    print(f\"interp shape: {volume.shape} >> {volume.dtype}\")\n",
    "    volume = crop_volume(volume, crop_thr)\n",
    "    print(f\"crop shape: {volume.shape} >> {volume.dtype}\")\n",
    "    vol_shape = volume.shape\n",
    "    interact(\n",
    "        lambda x, y, z: plt.show(show_volume(volume, x, y, z)),\n",
    "        x=IntSlider(min=0, max=vol_shape[0], step=5, value=int(vol_shape[0] / 2)),\n",
    "        y=IntSlider(min=0, max=vol_shape[1], step=5, value=int(vol_shape[1] / 2)),\n",
    "        z=IntSlider(min=0, max=vol_shape[2], step=5, value=int(vol_shape[2] / 2)),\n",
    "    )\n",
    "\n",
    "\n",
    "PATH_SAMPLE_VOLUME = os.path.join(PATH_DATASET, \"train\", \"00005\", \"FLAIR\")\n",
    "\n",
    "interactive_show(PATH_SAMPLE_VOLUME, crop_thr=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Union, Sequence, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class BrainScansDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_dir: str = 'train',\n",
    "        df_table: Union[str, pd.DataFrame] = 'train_labels.csv',\n",
    "        scan_types: Sequence[str] = (\"FLAIR\", \"T2w\"),\n",
    "        cache_dir: Optional[str] = None,\n",
    "        crop_thr: float = 1e-6,\n",
    "        mode: str = 'train',\n",
    "        split: float = 0.8,\n",
    "        in_memory: bool = False,\n",
    "        random_state=42,\n",
    "    ):\n",
    "        self.image_dir = image_dir\n",
    "        self.scan_types = scan_types\n",
    "        self.cache_dir = cache_dir\n",
    "        self.crop_thr = crop_thr\n",
    "        self.mode = mode\n",
    "        self.in_memory = in_memory\n",
    "\n",
    "        # set or load the config table\n",
    "        if isinstance(df_table, pd.DataFrame):\n",
    "            assert all(c in df_table.columns for c in [\"BraTS21ID\", \"MGMT_value\"])\n",
    "            self.table = df_table\n",
    "        elif isinstance(df_table, str):\n",
    "            assert os.path.isfile(df_table), f\"missing file: {df_table}\"\n",
    "            self.table = pd.read_csv(df_table)\n",
    "        else:\n",
    "            raise ValueError(f'unrecognised input for DataFrame/CSV: {df_table}')\n",
    "\n",
    "        # shuffle data\n",
    "        self.table = self.table.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "        # split dataset\n",
    "        assert 0.0 <= split <= 1.0, f\"split {split} is out of range\"\n",
    "        frac = int(split * len(self.table))\n",
    "        self.table = self.table[:frac] if mode == 'train' else self.table[frac:]\n",
    "\n",
    "        # populate images/labels\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        for _, row in self.table.iterrows():\n",
    "            id_ = row[\"BraTS21ID\"]\n",
    "            name = id_ if isinstance(id_, str) else \"%05d\" % id_\n",
    "            imgs = [os.path.join(name, tp) for tp in self.scan_types]\n",
    "            imgs = [p for p in imgs if os.path.isdir(os.path.join(self.image_dir, p))]\n",
    "            self.images += imgs\n",
    "            self.labels += [row[\"MGMT_value\"]] * len(imgs)\n",
    "        assert len(self.images) == len(self.labels)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_image(rltv_path: str, image_dir: str, cache_dir: str, crop_thr: float):\n",
    "        vol_path = os.path.join(cache_dir or \"\", f\"{rltv_path}.pt\")\n",
    "        if os.path.isfile(vol_path):\n",
    "            try:\n",
    "                return torch.load(vol_path)\n",
    "            except EOFError:\n",
    "                print(f\"failed loading: {vol_path}\")\n",
    "        img_path = os.path.join(image_dir, rltv_path)\n",
    "        assert os.path.isdir(img_path)\n",
    "        img = load_volume(img_path)\n",
    "        img = interpolate_volume(img)\n",
    "        if crop_thr is not None:\n",
    "            img = crop_volume(img, thr=crop_thr)\n",
    "        if cache_dir:\n",
    "            os.makedirs(os.path.dirname(vol_path), exist_ok=True)\n",
    "            torch.save(img, vol_path)\n",
    "        return img\n",
    "\n",
    "    def _load_image(self, rltv_path: str):\n",
    "        return BrainScansDataset.load_image(rltv_path, self.image_dir, self.cache_dir, self.crop_thr)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        label = self.labels[idx]\n",
    "        img = self.images[idx]\n",
    "        if isinstance(img, str):\n",
    "            img = self._load_image(img)\n",
    "        if self.in_memory:\n",
    "            self.images[idx] = img\n",
    "        # in case of predictions, return image name as label\n",
    "        label = label if label is not None else img_name\n",
    "        return {\"data\": img.unsqueeze(0), \"label\": label}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "ds = BrainScansDataset(\n",
    "    image_dir=os.path.join(PATH_DATASET, \"train\"),\n",
    "    df_table=os.path.join(PATH_DATASET, \"train_labels.csv\"),\n",
    "    crop_thr=None, cache_dir=PATH_TEMP,\n",
    ")\n",
    "for i in tqdm(range(2)):\n",
    "    img = ds[i * 10][\"data\"]\n",
    "    img = resize_volume(img[0])\n",
    "    show_volume(img, fig_size=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from typing import Optional, Sequence\n",
    "from pytorch_lightning import LightningDataModule\n",
    "import rising.transforms as rtr\n",
    "from rising.loading import DataLoader, default_transform_call\n",
    "from rising.random import DiscreteParameter, UniformParameter\n",
    "\n",
    "# define transformations\n",
    "VAL_TRANSFORMS = [\n",
    "    rtr.NormZeroMeanUnitStd(keys=[\"data\"]),\n",
    "]\n",
    "TRAIN_TRANSFORMS = [\n",
    "    rtr.NormZeroMeanUnitStd(keys=[\"data\"]),\n",
    "    # rtr.Rot90((0, 1, 2), keys=[\"data\"], p=0.5),\n",
    "    # rtr.Mirror(dims=DiscreteParameter([0, 1, 2]), keys=[\"data\"]),\n",
    "    # rtr.Rotate(UniformParameter(0, 180), degree=True),\n",
    "]\n",
    "\n",
    "\n",
    "def rising_resize(size: int = 64, **batch):\n",
    "    img = batch[\"data\"]\n",
    "    assert len(img.shape) == 4\n",
    "    img_ = []\n",
    "    for i in range(img.shape[0]):\n",
    "        img_.append(resize_volume(img[i], size))\n",
    "    batch.update({\"data\": torch.stack(img_, dim=0)})\n",
    "    return batch\n",
    "\n",
    "# ==============================\n",
    "\n",
    "\n",
    "class BrainScansDM(LightningDataModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str = '.',\n",
    "        path_csv: str = 'train_labels.csv',\n",
    "        cache_dir: str = '.',\n",
    "        scan_types: Sequence[str] = (\"FLAIR\", \"T2w\"),\n",
    "        crop_thr: float = 1e-6,\n",
    "        in_memory: bool = False,\n",
    "        input_size: int = 64,\n",
    "        batch_size: int = 4,\n",
    "        num_workers: int = None,\n",
    "        train_transforms=None,\n",
    "        valid_transforms=None,\n",
    "        split: float = 0.8,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # path configurations\n",
    "        assert os.path.isdir(data_dir), f\"missing folder: {data_dir}\"\n",
    "        self.train_dir = os.path.join(data_dir, 'train')\n",
    "        self.test_dir = os.path.join(data_dir, 'test')\n",
    "        self.cache_dir = cache_dir\n",
    "\n",
    "        if not os.path.isfile(path_csv):\n",
    "            path_csv = os.path.join(data_dir, path_csv)\n",
    "        assert os.path.isfile(path_csv), f\"missing table: {path_csv}\"\n",
    "        self.path_csv = path_csv\n",
    "\n",
    "        # other configs\n",
    "        self.scan_types = scan_types\n",
    "        self.crop_thr = crop_thr\n",
    "        self.input_size = input_size\n",
    "        self.batch_size = batch_size\n",
    "        self.split = split\n",
    "        self.in_memory = in_memory\n",
    "        self.num_workers = num_workers if num_workers is not None else os.cpu_count()\n",
    "\n",
    "        # need to be filled in setup()\n",
    "        self.train_dataset = None\n",
    "        self.valid_dataset = None\n",
    "        self.test_table = []\n",
    "        self.test_dataset = None\n",
    "        self.train_transforms = train_transforms\n",
    "        self.valid_transforms = valid_transforms\n",
    "            \n",
    "    def prepare_data(self, num_proc: int = 0):\n",
    "        if not self.cache_dir:\n",
    "            return\n",
    "        ds = BrainScansDataset(\n",
    "            image_dir=self.train_dir,\n",
    "            df_table=self.path_csv,\n",
    "            scan_types=self.scan_types,\n",
    "            split=1.0,\n",
    "            cache_dir=self.cache_dir,\n",
    "            crop_thr=self.crop_thr,\n",
    "            in_memory=False,\n",
    "        )\n",
    "        # for im in ds.images:\n",
    "        #     ds._load_image(im)\n",
    "\n",
    "        if num_proc > 1:\n",
    "            pool = Pool(processes=num_proc)\n",
    "            mapping = pool.imap_unordered\n",
    "        else:\n",
    "            pool = None\n",
    "            mapping = map\n",
    "\n",
    "        pbar = tqdm(desc=f\"preparing/caching scans @{num_proc} jobs\", total=len(ds))\n",
    "        _cache_img = partial(BrainScansDataset.load_image, image_dir=ds.image_dir, cache_dir=ds.cache_dir, crop_thr=ds.crop_thr)\n",
    "        for _ in mapping(_cache_img, ds.images):\n",
    "            pbar.update()\n",
    "\n",
    "        if pool:\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "\n",
    "    def setup(self, *_, **__) -> None:\n",
    "        \"\"\"Prepare datasets\"\"\"\n",
    "        ds_defaults = dict(\n",
    "            image_dir=self.train_dir,\n",
    "            df_table=self.path_csv,\n",
    "            scan_types=self.scan_types,\n",
    "            cache_dir=self.cache_dir,\n",
    "            crop_thr=self.crop_thr,\n",
    "            split=self.split,\n",
    "            in_memory=self.in_memory,\n",
    "        )\n",
    "        self.train_dataset = BrainScansDataset(**ds_defaults, mode='train')\n",
    "        logging.info(f\"training dataset: {len(self.train_dataset)}\")\n",
    "        self.valid_dataset = BrainScansDataset(**ds_defaults, mode='valid')\n",
    "        logging.info(f\"validation dataset: {len(self.valid_dataset)}\")\n",
    "\n",
    "        if not os.path.isdir(self.test_dir):\n",
    "            return\n",
    "        ls_cases = [os.path.basename(p) for p in glob.glob(os.path.join(self.test_dir, '*'))]\n",
    "        self.test_table = [dict(BraTS21ID=n, MGMT_value=0.5) for n in ls_cases]\n",
    "        self.test_dataset = BrainScansDataset(\n",
    "            image_dir=self.test_dir,\n",
    "            df_table=pd.DataFrame(self.test_table),\n",
    "            scan_types=self.scan_types,\n",
    "            cache_dir=self.cache_dir,\n",
    "            crop_thr=self.crop_thr,\n",
    "            split=0,\n",
    "            mode='test'\n",
    "        )\n",
    "        logging.info(f\"test dataset: {len(self.test_dataset)}\")\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "            sample_transforms=partial(rising_resize, size=self.input_size),  # todo: resize to fix size\n",
    "            batch_transforms=self.train_transforms,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.valid_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "            sample_transforms=partial(rising_resize, size=self.input_size),  # todo: resize to fix size\n",
    "            batch_transforms=self.valid_transforms,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> Optional[DataLoader]:\n",
    "        if not self.test_dataset:\n",
    "            logging.warning('no testing images found')\n",
    "            return None\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=0,\n",
    "            shuffle=False,\n",
    "            sample_transforms=partial(rising_resize, size=self.input_size),  # todo: resize to fix size\n",
    "            batch_transforms=self.valid_transforms,\n",
    "        )\n",
    "\n",
    "# ==============================\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "dm = BrainScansDM(\n",
    "    data_dir=PATH_DATASET,\n",
    "    scan_types=[\"T2w\"],\n",
    "    input_size=224,\n",
    "    crop_thr=1e-6,\n",
    "    batch_size=8,\n",
    "    cache_dir=PATH_TEMP,\n",
    "    # in_memory=True,\n",
    "    num_workers=2,\n",
    "    train_transforms=rtr.Compose(TRAIN_TRANSFORMS, transform_call=default_transform_call),\n",
    "    valid_transforms=rtr.Compose(VAL_TRANSFORMS, transform_call=default_transform_call),\n",
    ")\n",
    "# dm.prepare_data(2)\n",
    "dm.setup()\n",
    "\n",
    "# Quick view\n",
    "for batch in dm.train_dataloader():\n",
    "    for i in range(3):\n",
    "        show_volume(batch[\"data\"][i][0], fig_size=(9, 6), v_min_max=(-1., 1.))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare 3D model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy, F1, Precision\n",
    "from pytorch_lightning import LightningModule\n",
    "from efficientnet_pytorch_3d import EfficientNet3D\n",
    "\n",
    "\n",
    "class LitBrainMRI(LightningModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"efficientnet-b0\",\n",
    "        lr: float = 1e-4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model = EfficientNet3D.from_name(\"efficientnet-b0\", override_params={'num_classes': 2}, in_channels=1)\n",
    "        self.learning_rate = lr\n",
    "\n",
    "        self.train_accuracy = Accuracy()\n",
    "        self.train_precision = Precision()\n",
    "        self.train_f1_score = F1()\n",
    "        self.val_accuracy = Accuracy()\n",
    "        self.val_precision = Precision()\n",
    "        self.val_f1_score = F1()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return F.softmax(self.model(x))\n",
    "\n",
    "    def compute_loss(self, y_hat: Tensor, y: Tensor):\n",
    "        return F.cross_entropy(y_hat, y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        img, y = batch[\"data\"], batch[\"label\"]\n",
    "        y_hat = self(img)\n",
    "        loss = self.compute_loss(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=False)\n",
    "        self.log(\"train_acc\", self.train_accuracy(y_hat, y), prog_bar=False)\n",
    "        self.log(\"train_prec\", self.train_precision(y_hat, y), prog_bar=False)\n",
    "        self.log(\"train_f1\", self.train_f1_score(y_hat, y), prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        img, y = batch[\"data\"], batch[\"label\"]\n",
    "        y_hat = self(img)\n",
    "        loss = self.compute_loss(y_hat, y)\n",
    "        self.log(\"valid_loss\", loss, prog_bar=False)\n",
    "        self.log(\"valid_acc\", self.val_accuracy(y_hat, y), prog_bar=True)\n",
    "        self.log(\"valid_prec\", self.val_precision(y_hat, y), prog_bar=True)\n",
    "        self.log(\"valid_f1\", self.val_f1_score(y_hat, y), prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, self.trainer.max_epochs, 0)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "\n",
    "# ==============================\n",
    "from torchsummary import summary\n",
    "\n",
    "model = LitBrainMRI()\n",
    "# summary(model, input_size=(1, 128, 128, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "logger = pl.loggers.CSVLogger(save_dir='logs/', name=model.model_name)\n",
    "# swa = pl.callbacks.StochasticWeightAveraging(swa_epoch_start=0.6)\n",
    "ckpt = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='valid_f1',\n",
    "    save_top_k=1,\n",
    "    save_last=True,\n",
    "    # save_weights_only=True,\n",
    "    filename='checkpoint/{epoch:02d}-{valid_acc:.4f}-{valid_f1:.4f}',\n",
    "    # verbose=False,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    # fast_dev_run=True,\n",
    "    gpus=1,\n",
    "    callbacks=[ckpt],  # , swa\n",
    "    logger=logger,\n",
    "    max_epochs=3,\n",
    "    precision=16,\n",
    "    #overfit_batches=5,\n",
    "    accumulate_grad_batches=24,\n",
    "    val_check_interval=0.5,\n",
    "    progress_bar_refresh_rate=1,\n",
    "    weights_summary='top',\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "\n",
    "trainer.fit(model=model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.read_csv(f'{trainer.logger.log_dir}/metrics.csv')\n",
    "print(metrics.head())\n",
    "\n",
    "aggreg_metrics = []\n",
    "agg_col = \"epoch\"\n",
    "for i, dfg in metrics.groupby(agg_col):\n",
    "    agg = dict(dfg.mean())\n",
    "    agg[agg_col] = i\n",
    "    aggreg_metrics.append(agg)\n",
    "\n",
    "df_metrics = pd.DataFrame(aggreg_metrics)\n",
    "df_metrics[['train_loss', 'valid_loss']].plot(grid=True, legend=True, xlabel=agg_col)\n",
    "df_metrics[['valid_f1', 'valid_acc', 'valid_prec', 'train_acc']].plot(grid=True, legend=True, xlabel=agg_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
